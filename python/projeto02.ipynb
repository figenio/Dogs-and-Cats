{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ass Mateus e Yan\n",
    "\n",
    "# IMPORTAÇÕES\n",
    "import numpy as np\n",
    "import os, cv2, random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import  cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNÇÕES AUXILIARES\n",
    "\n",
    "\n",
    "#Opção de ler a imagem colorida ou em escala de cinza\n",
    "def read_image(file_path):\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
    "#    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "def prep_data(images):\n",
    "    count = len(images)\n",
    "    data = np.ndarray((count, CHANNELS, ROWS, COLS), dtype=np.uint8)\n",
    "\n",
    "    for i, image_file in enumerate(images):\n",
    "        image = read_image(image_file)\n",
    "        data[i] = image.T\n",
    "        if i%250 == 0: print('Processed {} of {}'.format(i, count))    \n",
    "    return data\n",
    "\n",
    "def show_cats_and_dogs(idx):\n",
    "    cat = read_image(train_cats[idx])\n",
    "    dog = read_image(train_dogs[idx])\n",
    "    pair = np.concatenate((cat, dog), axis=1)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.imshow(pair)\n",
    "    plt.show()\n",
    "    \n",
    "# dois exemplos de descritores. Você deve criar outros mais robustos.\n",
    "def image_to_feature_vector(image, size=(32, 32)):\n",
    "    # resize the image to a fixed size, then flatten the image into\n",
    "    # a list of raw pixel intensities\n",
    "    return cv2.resize(image, size).flatten()\n",
    "\n",
    "def extract_color_histogram(image, bins=(8, 8, 8)):     \n",
    "    # extract a 3D color histogram from the HSV color space using\n",
    "    # the supplied number of `bins` per channel\n",
    "    #image = cv2.imread(image_file)        \n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, bins,\n",
    "        [0, 180, 0, 256, 0, 256])\n",
    "    cv2.normalize(hist, hist)\n",
    "    # return the flattened histogram as the feature vector\n",
    "    return hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOSSOS DESCRITORES\n",
    "\n",
    "#CNN igual ao do slide\n",
    "def cnn_tf(image, image_size, image_nchannels):\n",
    "    \n",
    "    input_layer = tf.reshape(image, shape = [-1, image_size, image_size, image_nchannels])\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(inputs = input_layer,\n",
    "                             filters = 32,\n",
    "                             kernel_size = [3,3],\n",
    "                             padding = \"same\",\n",
    "                             activation = tf.nn.relu)\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(inputs = conv1,\n",
    "                                   pool_size = [2,2],\n",
    "                                   strides = 2)\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(inputs = pool1,\n",
    "                             filters = 64,\n",
    "                             kernel_size = [5,5],\n",
    "                             padding = \"same\",\n",
    "                             activation = tf.nn.relu)\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(inputs = conv2,\n",
    "                                   pool_size = [2,2],\n",
    "                                   strides = 2)\n",
    "    \n",
    "    flat = tf.contrib.layers.flatten(pool2)\n",
    "    \n",
    "#    return flat\n",
    "    \n",
    "    dense = tf.contrib.layers.fully_connected(inputs = flat,\n",
    "                                             num_outputs = 128,\n",
    "                                             activation_fn = tf.nn.relu)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 of 2000\n",
      "Processed 250 of 2000\n",
      "Processed 500 of 2000\n",
      "Processed 750 of 2000\n",
      "Processed 1000 of 2000\n",
      "Processed 1250 of 2000\n",
      "Processed 1500 of 2000\n",
      "Processed 1750 of 2000\n",
      "Train shape: (2000, 3, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "#MONTANDO A BASE DE TREINAMENTO\n",
    "\n",
    "#opção do número de imagens a serem usadas NIM\n",
    "\n",
    "TRAIN_DIR = 'kaggle/train/'\n",
    "\n",
    "ROWS = 128\n",
    "COLS = 128\n",
    "CHANNELS = 3\n",
    "NIM = 1000\n",
    "\n",
    "train_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)] #full dataset: dogs and cats\n",
    "train_dogs =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'dog' in i]\n",
    "train_cats =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'cat' in i]\n",
    "\n",
    "# considera apenas NIM imagens. Para o dataset completo, desconsiderar.\n",
    "train_images = train_dogs[:NIM] + train_cats[:NIM]\n",
    "random.shuffle(train_images)\n",
    "\n",
    "# Leitura das imagens\n",
    "train = prep_data(train_images)\n",
    "print(\"Train shape: {}\".format(train.shape))\n",
    "\n",
    "# Cria os labels (rótulos)\n",
    "labels = []\n",
    "for i in train_images:\n",
    "    if 'dog' in i:\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apenas mostra algumas imagens do conjunto de treinamento\n",
    "\n",
    "\n",
    "#for idx in range(0,3):\n",
    " #   show_cats_and_dogs(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 of 2000\n",
      "Processed 250 of 2000\n",
      "Processed 500 of 2000\n",
      "Processed 750 of 2000\n",
      "Processed 1000 of 2000\n",
      "Processed 1250 of 2000\n",
      "Processed 1500 of 2000\n",
      "Processed 1750 of 2000\n"
     ]
    }
   ],
   "source": [
    "#Aqui passa cada imagem pelos descritores e salva nos vetores abaixo\n",
    "\n",
    "rawImages = []\n",
    "descHist = []\n",
    "#cnnDesc = []\n",
    "\n",
    "count = len(train_images)\n",
    "\n",
    "for i, image_file in enumerate(train_images):\n",
    "    image = read_image(image_file)\n",
    "    pixels = image_to_feature_vector(image)\n",
    "    histogram = extract_color_histogram(image)\n",
    "    #neurons = cnn_tf(tf.cast(image, tf.float32), ROWS, CHANNELS)\n",
    "    \n",
    "    rawImages.append(pixels)\n",
    "    descHist.append(histogram)\n",
    "        \n",
    "    if i%250 == 0: print('Processed {} of {}'.format(i, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "KNeighborsClassifier\n",
      "****Results****\n",
      "accuracy: 53.60%\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "accuracy: 56.40%\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "accuracy: 58.00%\n"
     ]
    }
   ],
   "source": [
    "#Avalia o primeiro descritor: as imagens raw\n",
    "#Usa KNN, Arvore e Gaussian\n",
    "\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(\n",
    "    rawImages, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(17),    \n",
    "    DecisionTreeClassifier(),\n",
    "    GaussianNB()]\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    train_predictions = clf.predict(X_test)\n",
    "    acc = clf.score(X_test, y_test)\n",
    "    print(\"accuracy: {:.2f}%\".format(acc * 100))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "KNeighborsClassifier\n",
      "****Results****\n",
      "accuracy: 57.20%\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "accuracy: 62.80%\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "accuracy: 55.40%\n"
     ]
    }
   ],
   "source": [
    "#Avalia o segundo descritor: color histogram\n",
    "#Novamente com os três classificadores\n",
    "\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(\n",
    "    descHist, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(17),    \n",
    "    DecisionTreeClassifier(),\n",
    "    GaussianNB()]\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    train_predictions = clf.predict(X_test)\n",
    "    acc = clf.score(X_test, y_test)\n",
    "    print(\"accuracy: {:.2f}%\".format(acc * 100))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "KNeighborsClassifier\n",
      "****Results****\n",
      "accuracy: 54.20%\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "accuracy: 55.40%\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "accuracy: 58.60%\n"
     ]
    }
   ],
   "source": [
    "#Avalia a combinação dos dois primeiros descritores!\n",
    "\n",
    "#ATENÇÃO: ESTE É APENAS UM CÓDIGO EXEMPLO. VOCÊ DEVE DESENVOLVER\n",
    "#DESCRITORES MAIS ROBUSTOS, BEM COMO EXPLORAR MELHOR AS MÉTRICAS\n",
    "#DE AVALIAÇÃO (MATRIZ DE CONFUSÃO, ETC)\n",
    "\n",
    "trainAux = np.hstack((descHist, rawImages))\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(\n",
    "    trainAux, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(17),\n",
    "    DecisionTreeClassifier(),\n",
    "    GaussianNB()]\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    train_predictions = clf.predict(X_test)\n",
    "    acc = clf.score(X_test, y_test)\n",
    "    print(\"accuracy: {:.2f}%\".format(acc * 100))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [0, 2000]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-3a471028d464>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m (X_train, X_test, y_train, y_test) = train_test_split(\n\u001b[0;32m----> 2\u001b[0;31m     cnnDesc, labels, test_size=0.25, random_state=42)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m classifiers = [\n\u001b[1;32m      5\u001b[0m     \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mateus/.local/lib/python2.7/site-packages/sklearn/model_selection/_split.pyc\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2029\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2031\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2033\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mateus/.local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mateus/.local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [0, 2000]"
     ]
    }
   ],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(\n",
    "    train_images, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(17),    \n",
    "    DecisionTreeClassifier(),\n",
    "    GaussianNB()]\n",
    "   \n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    train_predictions = clf.predict(X_test)\n",
    "    acc = clf.score(X_test, y_test)\n",
    "    print(\"accuracy: {:.2f}%\".format(acc * 100))   "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
