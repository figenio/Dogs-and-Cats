{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ass Mateus e Yan\n",
    "\n",
    "# IMPORTAÇÕES\n",
    "import numpy as np\n",
    "import os, cv2, random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import  cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNÇÕES AUXILIARES\n",
    "\n",
    "\n",
    "#Opção de ler a imagem colorida ou em escala de cinza\n",
    "def read_image(file_path):\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
    "#    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "def prep_data(images):\n",
    "    count = len(images)\n",
    "    data = np.ndarray((count, CHANNELS, ROWS, COLS), dtype=np.uint8)\n",
    "\n",
    "    for i, image_file in enumerate(images):\n",
    "        image = read_image(image_file)\n",
    "        data[i] = image.T\n",
    "        if i%250 == 0: print('Processed {} of {}'.format(i, count))    \n",
    "    return data\n",
    "\n",
    "def show_cats_and_dogs(idx):\n",
    "    cat = read_image(train_cats[idx])\n",
    "    dog = read_image(train_dogs[idx])\n",
    "    pair = np.concatenate((cat, dog), axis=1)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.imshow(pair)\n",
    "    plt.show()\n",
    "    \n",
    "# dois exemplos de descritores. Você deve criar outros mais robustos.\n",
    "def image_to_feature_vector(image, size=(32, 32)):\n",
    "    # resize the image to a fixed size, then flatten the image into\n",
    "    # a list of raw pixel intensities\n",
    "    return cv2.resize(image, size).flatten()\n",
    "\n",
    "def extract_color_histogram(image, bins=(8, 8, 8)):     \n",
    "    # extract a 3D color histogram from the HSV color space using\n",
    "    # the supplied number of `bins` per channel\n",
    "    #image = cv2.imread(image_file)        \n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, bins,\n",
    "        [0, 180, 0, 256, 0, 256])\n",
    "    cv2.normalize(hist, hist)\n",
    "    # return the flattened histogram as the feature vector\n",
    "    return hist.flatten()   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOSSOS DESCRITORES\n",
    "\n",
    "#CNN igual ao do slide\n",
    "def cnn_tf(image, image_size, image_nchannels):\n",
    "    \n",
    "    input_layer = tf.reshape(image, shape = [-1, image_size, image_size, image_nchannels])\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(inputs = input_layer,\n",
    "                             filters = 32,\n",
    "                             kernel_size = [3,3],\n",
    "                             padding = \"same\",\n",
    "                             activation = tf.nn.relu)\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(inputs = conv1,\n",
    "                                   pool_size = [2,2],\n",
    "                                   strides = 2)\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(inputs = pool1,\n",
    "                             filters = 64,\n",
    "                             kernel_size = [5,5],\n",
    "                             padding = \"same\",\n",
    "                             activation = tf.nn.relu)\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(inputs = conv2,\n",
    "                                   pool_size = [2,2],\n",
    "                                   strides = 2)\n",
    "    \n",
    "    flat = tf.contrib,layers.flatten(pool2)\n",
    "    \n",
    "    return pool2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 of 2000\n",
      "Processed 250 of 2000\n",
      "Processed 500 of 2000\n",
      "Processed 750 of 2000\n",
      "Processed 1000 of 2000\n",
      "Processed 1250 of 2000\n",
      "Processed 1500 of 2000\n",
      "Processed 1750 of 2000\n",
      "Train shape: (2000, 3, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "#MONTANDO A BASE DE TREINAMENTO\n",
    "\n",
    "#opção do número de imagens a serem usadas NIM\n",
    "\n",
    "TRAIN_DIR = 'kaggle/train/'\n",
    "\n",
    "ROWS = 128\n",
    "COLS = 128\n",
    "CHANNELS = 3\n",
    "NIM = 1000\n",
    "\n",
    "train_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)] #full dataset: dogs and cats\n",
    "train_dogs =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'dog' in i]\n",
    "train_cats =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'cat' in i]\n",
    "\n",
    "# considera apenas NIM imagens. Para o dataset completo, desconsiderar.\n",
    "train_images = train_dogs[:NIM] + train_cats[:NIM]\n",
    "random.shuffle(train_images)\n",
    "\n",
    "# Leitura das imagens\n",
    "train = prep_data(train_images)\n",
    "print(\"Train shape: {}\".format(train.shape))\n",
    "\n",
    "# Cria os labels (rótulos)\n",
    "labels = []\n",
    "for i in train_images:\n",
    "    if 'dog' in i:\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apenas mostra algumas imagens do conjunto de treinamento\n",
    "\n",
    "\n",
    "#for idx in range(0,3):\n",
    " #   show_cats_and_dogs(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 of 2000\n",
      "Processed 250 of 2000\n",
      "Processed 500 of 2000\n",
      "Processed 750 of 2000\n",
      "Processed 1000 of 2000\n",
      "Processed 1250 of 2000\n",
      "Processed 1500 of 2000\n",
      "Processed 1750 of 2000\n"
     ]
    }
   ],
   "source": [
    "#Aqui passa cada imagem pelos descritores e salva nos vetores abaixo\n",
    "\n",
    "rawImages = []\n",
    "descHist = []\n",
    "cnnDesc = train_images\n",
    "\n",
    "count = len(train_images)\n",
    "\n",
    "for i, image_file in enumerate(train_images):\n",
    "    image = read_image(image_file)\n",
    "    pixels = image_to_feature_vector(image)\n",
    "    histogram = extract_color_histogram(image)\n",
    "    \n",
    "    rawImages.append(pixels)\n",
    "    descHist.append(histogram)\n",
    "        \n",
    "    if i%250 == 0: print('Processed {} of {}'.format(i, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "KNeighborsClassifier\n",
      "****Results****\n",
      "accuracy: 53.60%\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "accuracy: 56.40%\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "accuracy: 58.00%\n"
     ]
    }
   ],
   "source": [
    "#Avalia o primeiro descritor: as imagens raw\n",
    "#Usa KNN, Arvore e Gaussian\n",
    "\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(\n",
    "    rawImages, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(17),    \n",
    "    DecisionTreeClassifier(),\n",
    "    GaussianNB()]\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    train_predictions = clf.predict(X_test)\n",
    "    acc = clf.score(X_test, y_test)\n",
    "    print(\"accuracy: {:.2f}%\".format(acc * 100))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "KNeighborsClassifier\n",
      "****Results****\n",
      "accuracy: 57.20%\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "accuracy: 62.80%\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "accuracy: 55.40%\n"
     ]
    }
   ],
   "source": [
    "#Avalia o segundo descritor: color histogram\n",
    "#Novamente com os três classificadores\n",
    "\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(\n",
    "    descHist, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(17),    \n",
    "    DecisionTreeClassifier(),\n",
    "    GaussianNB()]\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    train_predictions = clf.predict(X_test)\n",
    "    acc = clf.score(X_test, y_test)\n",
    "    print(\"accuracy: {:.2f}%\".format(acc * 100))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "KNeighborsClassifier\n",
      "****Results****\n",
      "accuracy: 54.20%\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "accuracy: 55.40%\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "accuracy: 58.60%\n"
     ]
    }
   ],
   "source": [
    "#Avalia a combinação dos dois primeiros descritores!\n",
    "\n",
    "#ATENÇÃO: ESTE É APENAS UM CÓDIGO EXEMPLO. VOCÊ DEVE DESENVOLVER\n",
    "#DESCRITORES MAIS ROBUSTOS, BEM COMO EXPLORAR MELHOR AS MÉTRICAS\n",
    "#DE AVALIAÇÃO (MATRIZ DE CONFUSÃO, ETC)\n",
    "\n",
    "trainAux = np.hstack((descHist, rawImages))\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(\n",
    "    trainAux, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(17),\n",
    "    DecisionTreeClassifier(),\n",
    "    GaussianNB()]\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    train_predictions = clf.predict(X_test)\n",
    "    acc = clf.score(X_test, y_test)\n",
    "    print(\"accuracy: {:.2f}%\".format(acc * 100))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=['kaggle/train/dog.12298.jpg' 'kaggle/train/cat.6012.jpg'\n 'kaggle/train/cat.11923.jpg' ... 'kaggle/train/cat.9564.jpg'\n 'kaggle/train/cat.8248.jpg' 'kaggle/train/dog.5855.jpg'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-3a471028d464>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mateus/.local/lib/python2.7/site-packages/sklearn/neighbors/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \"\"\"\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mateus/.local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/home/mateus/.local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;31m# To ensure that array flags are maintained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=['kaggle/train/dog.12298.jpg' 'kaggle/train/cat.6012.jpg'\n 'kaggle/train/cat.11923.jpg' ... 'kaggle/train/cat.9564.jpg'\n 'kaggle/train/cat.8248.jpg' 'kaggle/train/dog.5855.jpg'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(\n",
    "    cnnDesc, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(17),    \n",
    "    DecisionTreeClassifier(),\n",
    "    GaussianNB()]\n",
    "   \n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    train_predictions = clf.predict(X_test)\n",
    "    acc = clf.score(X_test, y_test)\n",
    "    print(\"accuracy: {:.2f}%\".format(acc * 100))   "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
